{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gym-jsbsim in /home/jupyter-yash.gadhia/.local/lib/python3.6/site-packages (0.6.7)\n",
      "Requirement already satisfied: folium>=0.10.1 in /home/jupyter-yash.gadhia/.local/lib/python3.6/site-packages (from gym-jsbsim) (0.12.1.post1)\n",
      "Requirement already satisfied: shapely>=1.7.1 in /home/jupyter-yash.gadhia/.local/lib/python3.6/site-packages (from gym-jsbsim) (1.8.2)\n",
      "Requirement already satisfied: gym>=0.15.7 in /home/jupyter-yash.gadhia/.local/lib/python3.6/site-packages (from gym-jsbsim) (0.17.3)\n",
      "Requirement already satisfied: geographiclib>=1.50 in /home/jupyter-yash.gadhia/.local/lib/python3.6/site-packages (from gym-jsbsim) (1.52)\n",
      "Requirement already satisfied: jsbsim>=1.1.1 in /home/jupyter-yash.gadhia/.local/lib/python3.6/site-packages (from gym-jsbsim) (1.1.11)\n",
      "Requirement already satisfied: numpy in /opt/tljh/user/lib/python3.6/site-packages (from folium>=0.10.1->gym-jsbsim) (1.19.2)\n",
      "Requirement already satisfied: branca>=0.3.0 in /home/jupyter-yash.gadhia/.local/lib/python3.6/site-packages (from folium>=0.10.1->gym-jsbsim) (0.5.0)\n",
      "Requirement already satisfied: jinja2>=2.9 in /opt/tljh/user/lib/python3.6/site-packages (from folium>=0.10.1->gym-jsbsim) (2.10)\n",
      "Requirement already satisfied: requests in /opt/tljh/user/lib/python3.6/site-packages (from folium>=0.10.1->gym-jsbsim) (2.26.0)\n",
      "Requirement already satisfied: scipy in /opt/tljh/user/lib/python3.6/site-packages (from gym>=0.15.7->gym-jsbsim) (1.2.1)\n",
      "Requirement already satisfied: cloudpickle<1.7.0,>=1.2.0 in /home/jupyter-yash.gadhia/.local/lib/python3.6/site-packages (from gym>=0.15.7->gym-jsbsim) (1.6.0)\n",
      "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /home/jupyter-yash.gadhia/.local/lib/python3.6/site-packages (from gym>=0.15.7->gym-jsbsim) (1.5.0)\n",
      "Requirement already satisfied: setuptools in /opt/tljh/user/lib/python3.6/site-packages (from jsbsim>=1.1.1->gym-jsbsim) (41.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /opt/tljh/user/lib/python3.6/site-packages (from jinja2>=2.9->folium>=0.10.1->gym-jsbsim) (1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5; python_version >= \"3\" in /opt/tljh/user/lib/python3.6/site-packages (from requests->folium>=0.10.1->gym-jsbsim) (2.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/tljh/user/lib/python3.6/site-packages (from requests->folium>=0.10.1->gym-jsbsim) (2021.5.30)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/tljh/user/lib/python3.6/site-packages (from requests->folium>=0.10.1->gym-jsbsim) (1.26.9)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0; python_version >= \"3\" in /opt/tljh/user/lib/python3.6/site-packages (from requests->folium>=0.10.1->gym-jsbsim) (2.0.3)\n",
      "Requirement already satisfied: future in /opt/tljh/user/lib/python3.6/site-packages (from pyglet<=1.5.0,>=1.4.0->gym>=0.15.7->gym-jsbsim) (0.16.0)\n",
      "\u001b[33mWARNING: You are using pip version 19.3; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install gym-jsbsim --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gym==0.17.3 in /home/jupyter-yash.gadhia/.local/lib/python3.6/site-packages (0.17.3)\n",
      "Requirement already satisfied: numpy>=1.10.4 in /opt/tljh/user/lib/python3.6/site-packages (from gym==0.17.3) (1.19.2)\n",
      "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /home/jupyter-yash.gadhia/.local/lib/python3.6/site-packages (from gym==0.17.3) (1.5.0)\n",
      "Requirement already satisfied: cloudpickle<1.7.0,>=1.2.0 in /home/jupyter-yash.gadhia/.local/lib/python3.6/site-packages (from gym==0.17.3) (1.6.0)\n",
      "Requirement already satisfied: scipy in /opt/tljh/user/lib/python3.6/site-packages (from gym==0.17.3) (1.2.1)\n",
      "Requirement already satisfied: future in /opt/tljh/user/lib/python3.6/site-packages (from pyglet<=1.5.0,>=1.4.0->gym==0.17.3) (0.16.0)\n",
      "\u001b[33mWARNING: You are using pip version 19.3; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install gym==0.17.3 --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: You are using jsbsim-1.1.11 while gym-jsbsin was generated with 1.1.1\n"
     ]
    }
   ],
   "source": [
    "import pkg_resources\n",
    "pkg_resources.require(\"gym==0.17.3\")\n",
    "import gym\n",
    "import gym_jsbsim\n",
    "from gym_jsbsim.catalogs.catalog import Catalog as c\n",
    "import numpy as np\n",
    "import math\n",
    "import random\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PolicyNetwork(nn.Module):\n",
    "    def __init__(self,num_hidden_neurons):\n",
    "        super(PolicyNetwork, self).__init__()\n",
    "        self.layer1 = nn.Linear(9,num_hidden_neurons)\n",
    "        self.layer2 = nn.Linear(num_hidden_neurons,4)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x=torch.tanh(self.layer1(x))\n",
    "        x=torch.tanh(self.layer2(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "random.seed(0)\n",
    "torch.manual_seed(58308)\n",
    "model = PolicyNetwork(16)\n",
    "model.eval()\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "init_center = np.concatenate((model.layer1.weight.data.numpy().flatten(),model.layer2.weight.data.numpy().flatten(),model.layer1.bias.data.numpy(),model.layer2.bias.data.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vec_to_weights(vec,num_hidden_neurons):\n",
    "    w1 = torch.from_numpy(np.reshape(vec[0:num_hidden_neurons*9], (num_hidden_neurons, 9))).float()\n",
    "    w2 = torch.from_numpy(np.reshape(vec[num_hidden_neurons*9:13*num_hidden_neurons], (4, num_hidden_neurons))).float()\n",
    "    b1 = torch.from_numpy(np.reshape(vec[num_hidden_neurons*13:14*num_hidden_neurons], (num_hidden_neurons))).float()\n",
    "    b2 = torch.from_numpy(np.reshape(vec[num_hidden_neurons*14:14*num_hidden_neurons+4], (4))).float()\n",
    "    return w1,w2,b1,b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Obs_TupleToBoxWrapper(gym.ObservationWrapper):\n",
    "    def __init__(self, env):\n",
    "        super().__init__(env)\n",
    "        low = np.empty(shape=(0,))\n",
    "        high = np.empty(shape=(0,))\n",
    "        for i in env.observation_space:\n",
    "            low = np.concatenate([low,i.low])\n",
    "            high = np.concatenate([high,i.high])\n",
    "        self.observation_space = gym.spaces.Box(low=low, high=high, dtype=\"float\")\n",
    "        \n",
    "    \n",
    "    def observation(self, obs):\n",
    "        new_obs = np.empty(shape=(0,))\n",
    "        for i in obs:\n",
    "            new_obs = np.concatenate([new_obs,i])\n",
    "        return new_obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Act_TupleToBoxWrapper(gym.ActionWrapper):\n",
    "    def __init__(self, env):\n",
    "        super().__init__(env)\n",
    "        low = np.empty(shape=(0,))\n",
    "        high = np.empty(shape=(0,))\n",
    "        for i in env.action_space:\n",
    "            low = np.concatenate([low,i.low])\n",
    "            high = np.concatenate([high,i.high])\n",
    "        self.action_space = gym.spaces.Box(low=low, high=high, dtype=\"float\")\n",
    "        \n",
    "    \n",
    "    def action(self, act):\n",
    "        return act"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "env=Act_TupleToBoxWrapper(Obs_TupleToBoxWrapper(gym.make(\"GymJsbsim-HeadingControlTask-v0\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_and_take_action(env,curr_state,nn):\n",
    "    action = nn(torch.from_numpy(curr_state).float())\n",
    "    action.numpy()\n",
    "    action[-1]=(action[-1]+1)*0.45\n",
    "    state, reward, done, _ = env.step(action)\n",
    "    return state, reward, done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_episode(env,nn,find_and_take_action):\n",
    "    episode_reward = 0\n",
    "    state = env.reset()\n",
    "    #print(\"Initial State =\", state)\n",
    "    done = False\n",
    "    while not done:\n",
    "        state, reward, done = find_and_take_action(env,state,nn)\n",
    "        episode_reward += reward\n",
    "\n",
    "    delta_heading_altitude = (1/(abs(state[0])+1))*(1/(abs(state[1])+1))\n",
    "        \n",
    "    return env.get_sim_time(),episode_reward,delta_heading_altitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#muller-marsaglia method\n",
    "def spherepicking(n):\n",
    "    while True:           #to get rid off [0,0,0,0] case\n",
    "        l = [random.gauss(0, 1) for i in range(n)]\n",
    "        sumsq = sum([x * x for x in l])\n",
    "        if sumsq > 0:\n",
    "            break\n",
    "    norm = 1.0 / math.sqrt(sumsq)\n",
    "    pt = [x * norm for x in l]\n",
    "    return np.array(pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150.0000000000115\n",
      "168.50110852723716\n",
      "0.00018086107160599323\n"
     ]
    }
   ],
   "source": [
    "init_center_time, init_center_reward, init_delta_heading_altitude = run_episode(env,model,find_and_take_action)\n",
    "print(init_center_time)\n",
    "print(init_center_reward)\n",
    "print(init_delta_heading_altitude)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hill_climbing(env,lr,init_center,init_center_time,init_center_reward,init_delta_heading_altitude,model,num_hidden_neurons,num_points,epsilon):\n",
    "\n",
    "    center_is_best = False\n",
    "    num_weights = num_hidden_neurons*9 + 4*num_hidden_neurons + num_hidden_neurons + 4\n",
    "    step = 0\n",
    "    centers = []\n",
    "    times = []\n",
    "    episode_rewards = []\n",
    "    delta_heading_altitudes = []\n",
    "    center = init_center\n",
    "    time = init_center_time\n",
    "    episode_reward = init_center_reward\n",
    "    delta_heading_altitude = init_delta_heading_altitude\n",
    "    if time%150<epsilon:\n",
    "        at_checkpoint=True\n",
    "        checkpoint=time//150\n",
    "    else:\n",
    "        at_checkpoint=False\n",
    "        checkpoint = 0\n",
    "    centers.append(center)\n",
    "    times.append(time)\n",
    "    episode_rewards.append(episode_reward)\n",
    "    delta_heading_altitudes.append(delta_heading_altitude)\n",
    "    print(\"Step = \",step)\n",
    "    print(\"Simulation Time = \",time,\" sec\")\n",
    "    print(\"Reward = \",episode_reward)\n",
    "    if at_checkpoint:\n",
    "        print(\"Delta heading altitude = \",delta_heading_altitude)\n",
    "    \n",
    "\n",
    "    while not center_is_best:\n",
    "        \n",
    "        rewards = []\n",
    "        sim_time = []\n",
    "        dhas = []\n",
    "        points = []\n",
    "        for i in range(num_points):\n",
    "            point = center + lr*spherepicking(num_weights)\n",
    "            points.append(point)\n",
    "            w1, w2, b1, b2 = vec_to_weights(point,num_hidden_neurons)\n",
    "            model.layer1.weight.data = w1\n",
    "            model.layer2.weight.data = w2\n",
    "            model.layer1.bias.data = b1\n",
    "            model.layer2.bias.data = b2\n",
    "            t, r, dha = run_episode(env,model,find_and_take_action)\n",
    "            rewards.append(r)\n",
    "            sim_time.append(t)\n",
    "            dhas.append(dha)\n",
    "            \n",
    "        idx = -1\n",
    "        if at_checkpoint:\n",
    "            possible_idx1 = [i for i in range(num_points) if sim_time[i] >= ((150*checkpoint)+epsilon)]\n",
    "            possible_idx2 = [i for i in range(num_points) if (sim_time[i] >= (150*checkpoint)) and (sim_time[i] < ((150*checkpoint)+epsilon))]\n",
    "            if len(possible_idx1)>0:\n",
    "                max_reward = 0\n",
    "                for i in possible_idx1:\n",
    "                    if rewards[i]>max_reward:\n",
    "                        max_reward = rewards[i]\n",
    "                if max_reward>=episode_reward:\n",
    "                    idx = rewards.index(max_reward)\n",
    "                else:\n",
    "                    if len(possible_idx2)>0:\n",
    "                        max_dha = 0\n",
    "                        for i in possible_idx2:\n",
    "                            if dhas[i]>max_dha:\n",
    "                                max_dha = dhas[i]\n",
    "                        if max_dha>=delta_heading_altitude:\n",
    "                            idx = dhas.index(max_dha)\n",
    "            else:\n",
    "                if len(possible_idx2)>0:\n",
    "                    max_dha = 0\n",
    "                    for i in possible_idx2:\n",
    "                        if dhas[i]>max_dha:\n",
    "                            max_dha = dhas[i]\n",
    "                    if max_dha>=delta_heading_altitude:\n",
    "                        idx = dhas.index(max_dha)\n",
    "\n",
    "        else:\n",
    "            max_reward = max(rewards)\n",
    "            if max_reward>=episode_reward:\n",
    "                idx = rewards.index(max_reward)\n",
    "            \n",
    "        \n",
    "        if(idx==-1):\n",
    "            center_is_best = True\n",
    "        else:\n",
    "            step+=1\n",
    "            center = points[idx]\n",
    "            time = sim_time[idx]\n",
    "            episode_reward = rewards[idx]\n",
    "            delta_heading_altitude = dhas[idx]            \n",
    "            print(\"Step = \",step)\n",
    "            print(\"Simulation Time = \",time,\" sec\")\n",
    "            print(\"Reward = \",episode_reward)\n",
    "            if time%150<epsilon:\n",
    "                at_checkpoint=True\n",
    "                checkpoint=time//150\n",
    "            else:\n",
    "                at_checkpoint=False\n",
    "                checkpoint = 0\n",
    "            if at_checkpoint:\n",
    "                print(\"Delta heading altitude = \",delta_heading_altitude)\n",
    "            centers.append(center)\n",
    "            times.append(time)\n",
    "            episode_rewards.append(episode_reward)\n",
    "            delta_heading_altitudes.append(delta_heading_altitude)\n",
    "            \n",
    "    return centers, times, episode_rewards, delta_heading_altitudes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step =  0\n",
      "Simulation Time =  150.0000000000115  sec\n",
      "Reward =  168.50110852723716\n",
      "Delta heading altitude =  0.00018086107160599323\n",
      "Step =  1\n",
      "Simulation Time =  166.16666666669104  sec\n",
      "Reward =  849.1886858760104\n",
      "Step =  2\n",
      "Simulation Time =  450.08333333325265  sec\n",
      "Reward =  996.6629582735893\n",
      "Delta heading altitude =  0.0008231450064820971\n"
     ]
    }
   ],
   "source": [
    "centers, times, episode_rewards, delta_heading_altitudes = hill_climbing(env,1,init_center,init_center_time,init_center_reward,init_delta_heading_altitude,model,16,25000,0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step =  0\n",
      "Simulation Time =  450.08333333325265  sec\n",
      "Reward =  996.6629582735893\n",
      "Delta heading altitude =  0.0008231450064820971\n",
      "Step =  1\n",
      "Simulation Time =  450.08333333325265  sec\n",
      "Reward =  777.2390819436755\n",
      "Delta heading altitude =  0.012910315730236767\n",
      "Step =  2\n",
      "Simulation Time =  624.1666666664277  sec\n",
      "Reward =  2057.0789794581638\n"
     ]
    }
   ],
   "source": [
    "centers_new, times_new, episode_rewards_new, delta_heading_altitudes_new = hill_climbing(env,0.5,centers[-1],times[-1],episode_rewards[-1],delta_heading_altitudes[-1],model,16,25000,0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step =  0\n",
      "Simulation Time =  624.1666666664277  sec\n",
      "Reward =  2057.0789794581638\n",
      "Step =  1\n",
      "Simulation Time =  1060.3333333326977  sec\n",
      "Reward =  3781.9506939934195\n",
      "Step =  2\n",
      "Simulation Time =  1511.5833333322873  sec\n",
      "Reward =  4538.95719481957\n",
      "Step =  3\n",
      "Simulation Time =  1360.666666665758  sec\n",
      "Reward =  4637.431188657872\n",
      "Step =  4\n",
      "Simulation Time =  1518.4999999989477  sec\n",
      "Reward =  4764.115926805554\n",
      "Step =  5\n",
      "Simulation Time =  2705.5833333401724  sec\n",
      "Reward =  5858.75858017614\n",
      "Step =  6\n",
      "Simulation Time =  1800.083333332025  sec\n",
      "Reward =  6838.863256071615\n",
      "Delta heading altitude =  0.009881892434263032\n",
      "Step =  7\n",
      "Simulation Time =  7500.249999975004  sec\n",
      "Reward =  8427.502652427962\n",
      "Delta heading altitude =  0.0001312816931876806\n"
     ]
    }
   ],
   "source": [
    "centers_new_new, times_new_new, episode_rewards_new_new, delta_heading_altitudes_new_new = hill_climbing(env,0.25,centers_new[-1],times_new[-1],episode_rewards_new[-1],delta_heading_altitudes_new[-1],model,16,25000,0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step =  0\n",
      "Simulation Time =  7500.249999975004  sec\n",
      "Reward =  8427.502652427962\n",
      "Delta heading altitude =  0.0001312816931876806\n",
      "Step =  1\n",
      "Simulation Time =  7542.4999999743895  sec\n",
      "Reward =  17613.03651317054\n",
      "Step =  2\n",
      "Simulation Time =  7079.916666647788  sec\n",
      "Reward =  20207.574301389166\n",
      "Step =  3\n",
      "Simulation Time =  7544.333333307696  sec\n",
      "Reward =  23470.4845696408\n"
     ]
    }
   ],
   "source": [
    "centers_new_new_new, times_new_new_new, episode_rewards_new_new_new, delta_heading_altitudes_new_new_new = hill_climbing(env,0.1,centers_new_new[-1],times_new_new[-1],episode_rewards_new_new[-1],delta_heading_altitudes_new_new[-1],model,16,25000,0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[7500.249999975004, 7542.4999999743895, 7079.916666647788, 7544.333333307696]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "times_new_new_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {\"centers_final\": centers + centers_new + centers_new_new + centers_new_new_new,\n",
    "     \"times_final\": times + times_new + times_new_new + times_new_new_new,\n",
    "     \"episode_rewards_final\": episode_rewards + episode_rewards_new + episode_rewards_new_new + episode_rewards_new_new_new,\n",
    "     \"delta_heading_altitudes_final\" : delta_heading_altitudes + delta_heading_altitudes_new + delta_heading_altitudes_new_new + delta_heading_altitudes_new_new_new}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('./weights/58308.pickle', 'wb') as handle:\n",
    "    pickle.dump(d, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
